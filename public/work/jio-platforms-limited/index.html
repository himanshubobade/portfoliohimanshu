<!DOCTYPE html>
<html lang="en">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8" />
    <title>Work At JPL | </title>
    <link rel="stylesheet" href="http://localhost:1313/css/main.css">
    <link rel="stylesheet" href="http://localhost:1313/css/rad-icons.css">
  </head>
  <body>
    <header class="header fixed-top rad-animation-group" id="header">
  <div class="container rad-fade-in">
    <nav class="navbar navbar-expand-lg navbar-light p-0">
      <a class="navbar-brand" href="http://localhost:1313/">
        <span>Himanshu</span>
        <span>Bobade</span>
        
      </a>
      <button
        class="navbar-toggler"
        type="button"
        data-toggle="collapse"
        data-target="#navbarSupportedContent, #header"
        aria-controls="navbarSupportedContent"
        aria-expanded="false"
        aria-label="Toggle navigation"
      >
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-lg-auto">
          <li class="nav-item">
            <a class="nav-link" href="http://localhost:1313/">HOME</a>
          </li>
          
          
          <li class="nav-item">
            
          
            
            
              
            
          
            
            <a class="nav-link" href="http://localhost:1313/#experience" data-scroll>
              EXPERIENCE
            </a>
          </li>
          
          <li class="nav-item">
            
          
            
            
              
            
          
            
            <a class="nav-link" href="http://localhost:1313/#portfolio" data-scroll>
              ACHIEVEMENTS
            </a>
          </li>
          
          <li class="nav-item">
            
          
            
            
              
            
          
            
            <a class="nav-link" href="http://localhost:1313/#portfolio" data-scroll>
              PROJECTS
            </a>
          </li>
          
        </ul>
      </div>
    </nav>
  </div>
</header>


    <section class="section">
      <div class="container">

        
        <h1 class="mb-4 display-1" style="font-weight: 200;">Work At JPL</h1>
        
        <div class="row mb-5">
          
          <div class="col-md-6">
            <p>
              Honored to have received a spot award at JPL’s 2023 product conference for my work in Data Engineering and Cloud Platform Engineering. This recognition highlighted the design and implementation of robust data pipelines, as well as the adoption of cutting-edge cloud technologies that enhance scalability and efficiency. I’m deeply grateful for the supportive and pioneering team I’ve had the privilege to collaborate with, and proud that our collective efforts continue to drive innovation in this exciting domain.
            </p>
          </div>
          
          
          <div class="col-md-6 mt-3 mt-md-0 text-center">
            
            <img
              src="http://localhost:1313/images/jplAward.jpeg"
              alt="Work Overview"
              class="img-fluid"
              
            >
            
          </div>
        </div>
        
        
        
          <h2 class="mt-4" style="color: #e93e34; font-weight: 500;">Use-Case Engineering</h2>

          
          
            <h3 class="mt-3">A) Fibre</h3>

            
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">1] TAT Status</h4>
                <p>Optimized Fibre Service Efficiency: Streamlined a 52-step tracking process by integrating real-time monitoring for technician service status. Engineered a data pipeline with Spark, Scala, Kafka, Airflow, APIs, Hive, and MySQL, ensuring seamless synchronization across 5 disparate systems with CI/CD testing. Enhanced service resolution efficiency, impacting 4.3 million users with real-time tracking and proactive alerts. </p>

                
                
                  <img src="http://localhost:1313/images/Fibre.png" alt="1] TAT Status" class="img-fluid mb-3">
                
              </div>
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">2] Live Device Theft Prevention</h4>
                <p>Built a real-time Geofencing alert system to detect unauthorized device movement across geographical regions. Leveraged Spark, Hive, Kafka, Scala, and Airflow to process live location updates, reducing device theft incidents and enhancing security monitoring. </p>

                
                
                  <img src="http://localhost:1313/images/Theft.png" alt="2] Live Device Theft Prevention" class="img-fluid mb-3">
                
              </div>
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">3] Location-Based Customer Segmentation</h4>
                <p>Developed a customer profiling solution by tracking day and night locations using public Kafka streams. Integrated NiFi, Kafka, Spark, Scala, Airflow, and Hive to process and analyze location data, enabling targeted premium service offerings based on user affordability and behavior insights. </p>

                
                
                  <img src="http://localhost:1313/images/Location.png" alt="3] Location-Based Customer Segmentation" class="img-fluid mb-3">
                
              </div>
            
          
            <h3 class="mt-3">B) Migration Projects (HDP to CDP)</h3>

            
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">1] Network Tower Optimization, GIS, JPW, OrderCare, and WorkOrder</h4>
                <p> Engineered scalable data pipelines for Network Tower Optimization, GIS, OrderCare, and WorkOrder, capturing KPIs to support enterprise-wide decision-making. Employed Spark, NiFi, Scala, Hive, MySQL, Kafka, and Airflow to aggregate and process critical mobility data. Additionally, directed migration efforts from HDP to CDP, ensuring seamless system transition and improved performance.Implemented metadata tracking and data lineage frameworks to boost data governance and compliance. </p>

                
                
                  <img src="http://localhost:1313/images/Migration.png" alt="1] Network Tower Optimization, GIS, JPW, OrderCare, and WorkOrder" class="img-fluid mb-3">
                
              </div>
            
          
        
          <h2 class="mt-4" style="color: #e93e34; font-weight: 500;">Platform Engineering</h2>

          
          
            <h3 class="mt-3">A) Hybrid Pipeline</h3>

            
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">1] HDP to Azure Live Streaming with Flink</h4>
                <p>Engineered a high-performance Apache Flink-based real-time data pipeline to bridge on-prem Hive and Oracle MySQL via Azure Synapse. Designed a 24x7 running Azure Notebook to process and sync Kafka-based data, achieving a peak processing capability of 500 million records daily. Executed robust checkpointing mechanisms to ensure fault tolerance and data integrity. </p>

                
                
                  <img src="http://localhost:1313/images/Hybrid.png" alt="1] HDP to Azure Live Streaming with Flink" class="img-fluid mb-3">
                
              </div>
            
          
            <h3 class="mt-3">B) Data Quality - GCP</h3>

            
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">1] GCP - Data Fusion</h4>
                <p>Adopted two methods to capture DataFusion metrics. The primary approach involved running a Dataproc job that queries a CDAP endpoint to gather instance, namespace, project, pipeline, and job-level metrics. These metrics are then ingested into BigQuery and displayed in Looker Studio for real-time data ingestion monitoring. This setup flags anomalies quickly and streamlines root-cause analysis.</p>

                
                
                  <img src="http://localhost:1313/images/Data%20Fusion.png" alt="1] GCP - Data Fusion" class="img-fluid mb-3">
                
              </div>
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">2] GCP - Data Flow</h4>
                <p>Relied on Cloud Monitoring Metrics to capture and segregate Data Flow metrics at the job ID level. Used SQL-like queries against these metrics, funneling them into Looker Studio for detailed visualization. This method ensures thorough oversight of each job’s data ingestion and processing behavior.</p>

                
                
                  <img src="http://localhost:1313/images/DataFlow.png" alt="2] GCP - Data Flow" class="img-fluid mb-3">
                
              </div>
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">3] GCP - DataProc</h4>
                <p>Addressed an Apache Spark metrics bug within Dataproc by crafting custom Spark Listeners. Packaged these listeners with each Dataproc job to collect key runtime metrics, which were then stored in BigQuery. Looker Studio dashboards provided a comprehensive view of these metrics, ensuring any irregularities were caught promptly.</p>

                
                
                  <img src="http://localhost:1313/images/DataProc.png" alt="3] GCP - DataProc" class="img-fluid mb-3">
                
              </div>
            
          
            <h3 class="mt-3">C) Data Quality - Azure Synapse</h3>

            
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">1] Azure Synapse - CopyActivity</h4>
                <p>Established a metrics-logging framework for pipelines using Copy Activity. Logged pipeline metrics into SQL Pool, then performed Z-score–based anomaly detection. The final results were displayed in dashboards, enabling quick identification of unexpected trends in data loads.</p>

                
                
                  <img src="http://localhost:1313/images/CopyActivity.png" alt="1] Azure Synapse - CopyActivity" class="img-fluid mb-3">
                
              </div>
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">2] Azure Synapse - Data Flow</h4>
                <p>Created a reusable DataFlow-based solution attachable to any production pipeline. It captures logs from various sources and sinks, then processes them in an Azure notebook. The processed data goes into SQL Pool, where Z-score analysis highlights anomalies, and visual dashboards present the outcomes.</p>

                
                
                  <img src="http://localhost:1313/images/AzureDataFlow.png" alt="2] Azure Synapse - Data Flow" class="img-fluid mb-3">
                
              </div>
            
          
            <h3 class="mt-3">D) Data Quality - OnPrem</h3>

            
            
              
              

              <div class="mb-4 pl-3">
                <h4 style="color: #f07871;">1] Kafka Metrics Monitoring</h4>
                <p>Introduced a mechanism to verify data completeness between Kafka producers and consumers, ensuring no data leakage. Used shell scripts and HQL queries to calculate offsets in Kafka topics, storing them in HQL tables for monitoring. This approach quickly reveals ingestion discrepancies and safeguards data integrity.</p>

                
                
                  <img src="http://localhost:1313/images/KafkaMetrics.png" alt="1] Kafka Metrics Monitoring" class="img-fluid mb-3">
                
              </div>
            
          
        

      </div>
    </section>

    <footer class="footer">
  <div class="container">
    
    <div class="footer__links">
      <ul class="navbar-nav ">
        <li class="nav-item">
          <a class="nav-link" href="/">HOME</a>
        </li>
        
        <li class="nav-item">
          <a class="nav-link" href="http://localhost:1313/#experience">EXPERIENCE</a>
        </li>
        
        <li class="nav-item">
          <a class="nav-link" href="http://localhost:1313/#portfolio">ACHIEVEMENTS</a>
        </li>
        
        <li class="nav-item">
          <a class="nav-link" href="http://localhost:1313/#portfolio">PROJECTS</a>
        </li>
        
      </ul>
    </div>
    
  </div>
</footer>

    <script src='http://localhost:1313/js/rad-animations.js'></script>
<script src='http://localhost:1313/js/library/lozad.min.js'></script>
<script>
  window.addEventListener("load", function() {
    var observer = window.lozad(".lozad", {
      rootMargin: window.innerHeight / 2 + "px 0px",
      threshold: 0.01
    }); 
    observer.observe();
  });
</script>
<script src='http://localhost:1313/js/library/jquery-3.3.1.slim.min.js'></script>
<script src='http://localhost:1313/js/library/bootstrap.min.js'></script>
<script src='http://localhost:1313/js/sticky-header.js'></script>
<script src='http://localhost:1313/js/library/smooth-scroll.polyfills.min.js'></script>
<script src='http://localhost:1313/js/library/fontfaceobserver.js'></script>
<script>
  (function(w) {
    
    if (w.document.documentElement.className.indexOf("fonts-loaded") > -1) {
      return;
    }
    var fontA = new w.FontFaceObserver("Inter", {
      weight: 300
    });
    var fontB = new w.FontFaceObserver("Inter", {
      weight: 400
    });
    var fontC = new w.FontFaceObserver("Inter", {
      weight: 500
    });
    var fontD = new w.FontFaceObserver("Inter", {
      weight: 600
    });
    var fontE = new w.FontFaceObserver("Inter", {
      weight: 700
    });
    var fontF = new w.FontFaceObserver("Inter", {
      weight: 900
    });
    w.Promise.all([fontA.load(), fontC.load(), fontF.load()]).then(function() {
      w.document.documentElement.className += " fonts-loaded";
    });
  })(this);
</script>
<script>
  const scroll = new SmoothScroll('a[href*="#"]');
    $('a.nav-link').on('click', () => {
      const navbar = $('.navbar-collapse');
      if (navbar && navbar.hasClass('show')) {
        $('.navbar-toggler').click();
      }
    })
</script>

  </body>
</html>
